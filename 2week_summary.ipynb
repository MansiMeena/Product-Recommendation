{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import operator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import log_loss, f1_score, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45619, 22) (45619, 1) (929615, 22)\n"
     ]
    }
   ],
   "source": [
    "trn = pd.read_csv(\"../input/train_clean.csv\")\n",
    "target = pd.read_csv(\"../input/train.csv\", usecols=[\"target\"])\n",
    "tst = pd.read_csv(\"../input/test_clean.csv\")\n",
    "test_id = tst[\"ncodpers\"]\n",
    "tst.drop([\"ncodpers\"], axis=1, inplace=True)\n",
    "trn.drop([\"ncodpers\"], axis=1, inplace=True)\n",
    "\n",
    "print(trn.shape, target.shape, tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 데이터와 Test 데이터의 컬럼이 동일해야 하므로 확인을 해봐야 합니다 :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn.columns == tst.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn의 경우 수치형 데이터가 아니면 들어가질 않기 때문에\n",
    "\n",
    "수치형이 아닌 친구를 확인해봐요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_dato\n",
      "ind_empleado\n",
      "pais_residencia\n",
      "sexo\n",
      "fecha_alta\n",
      "ult_fec_cli_1t\n",
      "tiprel_1mes\n",
      "indresi\n",
      "indext\n",
      "conyuemp\n",
      "canal_entrada\n",
      "indfall\n",
      "nomprov\n",
      "segmento\n"
     ]
    }
   ],
   "source": [
    "for col in trn.columns:\n",
    "    if trn[col].dtype == \"object\":\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in trn.columns:\n",
    "    if trn[col].dtype == \"object\":\n",
    "        lb = LabelEncoder()\n",
    "        lb.fit(pd.concat([trn[col], tst[col]])) # 테스트와 트레인 데이터를 아래로 합침\n",
    "        trn[col] = lb.transform(trn[col]) # 컬럼을 덮어씌움\n",
    "        tst[col] = lb.transform(tst[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fecha_dato int64 int64\n",
      "ind_empleado int64 int64\n",
      "pais_residencia int64 int64\n",
      "sexo int64 int64\n",
      "age int64 int64\n",
      "fecha_alta int64 int64\n",
      "ind_nuevo int64 int64\n",
      "antiguedad int64 int64\n",
      "indrel int64 int64\n",
      "ult_fec_cli_1t int64 int64\n",
      "indrel_1mes int64 int64\n",
      "tiprel_1mes int64 int64\n",
      "indresi int64 int64\n",
      "indext int64 int64\n",
      "conyuemp int64 int64\n",
      "canal_entrada int64 int64\n",
      "indfall int64 int64\n",
      "cod_prov int64 int64\n",
      "nomprov int64 int64\n",
      "ind_actividad_cliente int64 int64\n",
      "renta float64 float64\n",
      "segmento int64 int64\n"
     ]
    }
   ],
   "source": [
    "# 이제 변수 타입들 다시 확인\n",
    "for col in trn.columns:\n",
    "    print(col, trn[col].dtype, tst[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 9452\n",
      "3 9\n",
      "4 1934\n",
      "5 55\n",
      "6 349\n",
      "7 222\n",
      "8 154\n",
      "9 503\n",
      "10 33\n",
      "11 1085\n",
      "12 1219\n",
      "13 246\n",
      "14 4\n",
      "15 21\n",
      "16 8\n",
      "17 2942\n",
      "18 4733\n",
      "19 159\n",
      "20 3\n",
      "21 5151\n",
      "22 8218\n",
      "23 9119\n"
     ]
    }
   ],
   "source": [
    "# target을 이제 확인해봐요\n",
    "\n",
    "for t in np.unique(target):\n",
    "    print(t, sum(target[\"target\"]==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Byeon\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:129: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# 빈도가 적은 데이터 제거\n",
    "rem_targets = [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]  # 18 classes\n",
    "trn = trn[target[\"target\"].isin(rem_targets)]\n",
    "target = target[target[\"target\"].isin(rem_targets)]\n",
    "target = LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(x, y, model):\n",
    "    trn_scores = dict(); vld_scores = dict()\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.1, random_state=777) # 10% 테스트, random_state 는 시드값\n",
    "    for t_ind, v_ind in sss.split(x,y):\n",
    "        # split data\n",
    "        x_trn, x_vld = x.iloc[t_ind], x.iloc[v_ind]\n",
    "        y_trn, y_vld = y[t_ind], y[v_ind]\n",
    "\n",
    "        # fit model\n",
    "        model.fit(x_trn, y_trn) # train만 학습시킵니다!\n",
    "        \n",
    "        # eval _ trn\n",
    "        preds = model.predict(x_trn)\n",
    "        acc_scores = trn_scores.get('accuracy', [])\n",
    "        acc_scores.append(accuracy_score(y_trn, preds))\n",
    "        trn_scores['accuracy'] = acc_scores\n",
    "\n",
    "        f1_scores = trn_scores.get('f1 score', [])\n",
    "        f1_scores.append(f1_score(y_trn, preds, average='weighted'))\n",
    "        trn_scores['f1 score'] = f1_scores\n",
    "        \n",
    "        preds = model.predict_proba(x_trn)\n",
    "\n",
    "        log_scores = trn_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_trn, preds))\n",
    "        trn_scores['log loss'] = log_scores\n",
    "\n",
    "        # eval _ vld\n",
    "        preds = model.predict(x_vld) # predice된 값을 y_vld랑 비교\n",
    "        acc_scores = vld_scores.get('accuracy', [])\n",
    "        acc_scores.append(accuracy_score(y_vld, preds))\n",
    "        vld_scores['accuracy'] = acc_scores\n",
    "\n",
    "        f1_scores = vld_scores.get('f1 score', [])\n",
    "        f1_scores.append(f1_score(y_vld, preds, average='weighted'))\n",
    "        vld_scores['f1 score'] = f1_scores\n",
    "        \n",
    "        preds = model.predict_proba(x_vld)\n",
    "\n",
    "        log_scores = vld_scores.get('log loss', [])\n",
    "        log_scores.append(log_loss(y_vld, preds))\n",
    "        vld_scores['log loss'] = log_scores\n",
    "    return trn_scores, vld_scores\n",
    "\n",
    "def print_scores(trn_scores, vld_scores):\n",
    "    prefix = '        '\n",
    "    cols = ['accuracy', 'f1 score','log loss']\n",
    "    print('='*50)\n",
    "    print('TRAIN EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(trn_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, trn_scores[col]))\n",
    "\n",
    "    print('='*50)\n",
    "    print('VALID EVAL')\n",
    "    for col in cols:\n",
    "        print('-'*50)\n",
    "        print('# {}'.format(col))\n",
    "        print('# {} Mean : {}'.format(prefix, np.mean(vld_scores[col])))\n",
    "        print('# {} Raw  : {}'.format(prefix, vld_scores[col]))\n",
    "\n",
    "def print_time(end, start):\n",
    "    print('='*50)\n",
    "    elapsed = end - start\n",
    "    print('{} secs'.format(round(elapsed)))\n",
    "    \n",
    "def fit_and_eval(trn, target, model):\n",
    "    trn_scores, vld_scores = evaluate(trn,target,model)\n",
    "    print_scores(trn_scores, vld_scores)\n",
    "    print_time(time.time(), st)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Byeon\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "TRAIN EVAL\n",
      "--------------------------------------------------\n",
      "# accuracy\n",
      "#          Mean : 0.2689817635351935\n",
      "#          Raw  : [0.26660168149140978, 0.27308395272328501, 0.26725965639088584]\n",
      "--------------------------------------------------\n",
      "# f1 score\n",
      "#          Mean : 0.1935636190100405\n",
      "#          Raw  : [0.18744667752682029, 0.20518539950478837, 0.18805877999851281]\n",
      "--------------------------------------------------\n",
      "# log loss\n",
      "#          Mean : 2.0239253340972945\n",
      "#          Raw  : [2.0252648324052274, 2.0237462642254758, 2.0227649056611798]\n",
      "==================================================\n",
      "VALID EVAL\n",
      "--------------------------------------------------\n",
      "# accuracy\n",
      "#          Mean : 0.26622807017543865\n",
      "#          Raw  : [0.26337719298245615, 0.27543859649122809, 0.25986842105263158]\n",
      "--------------------------------------------------\n",
      "# f1 score\n",
      "#          Mean : 0.19096039754864078\n",
      "#          Raw  : [0.18323018001326635, 0.20681280442409578, 0.18283820820856014]\n",
      "--------------------------------------------------\n",
      "# log loss\n",
      "#          Mean : 2.0253845878611636\n",
      "#          Raw  : [2.0192749821789748, 2.0252751868334657, 2.0316035945710502]\n",
      "==================================================\n",
      "65 secs\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1, random_state=777) #n_jobs= -1 인 경우 자싱니 가진 모든 cpu를 사용함\n",
    "fit_and_eval(trn, target, model)\n",
    "# 58 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 검증 데이터의 평가 척도가 비슷한지 확인을 해야합니다-!\n",
    "\n",
    "너무 다른 경우 오버피팅의 가능성이 존재해요\n",
    "\n",
    "\n",
    "로지스틱 regression에서 C의 값은 regularization의 역수임\n",
    "\n",
    "지금 과적합 상태라면 c의 값을 낮추면 정규성이 증가됨~!!\n",
    "\n",
    "모델은 복잡도 기준으로 바라볼 것\n",
    "\n",
    "sroted Feature importance 기준으로 볼 경우 변수의 scale이 다른데 그냥 한번에 돌림..! normalize를 하고 다시 돌려볼 것\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility\n",
    "\n",
    "def observe_model_lr(model):\n",
    "    target_num = 0\n",
    "    print('='*50)\n",
    "    print(model)\n",
    "    \n",
    "    print('='*50)\n",
    "    print('# Coefficients for target_num == {}'.format(target_num))\n",
    "    print(model.coef_[target_num])\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('# Mapped to Column Name')\n",
    "    prefix = '    '\n",
    "    coefs = dict()\n",
    "    for i, coef in enumerate(model.coef_[target_num]):\n",
    "        print('{} {} \\t {}'.format(prefix, round(coef,5), trn.columns[i]))\n",
    "        coefs[trn.columns[i]] = np.absolute(coef)\n",
    "\n",
    "    print('-'*50)\n",
    "    print('# Sorted Feature Importance')\n",
    "    coefs_sorted = sorted(coefs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    for item in coefs_sorted:\n",
    "        print('{} {} \\t {}'.format(prefix, round(item[1],5), item[0]))\n",
    "    \n",
    "    return coefs_sorted\n",
    "\n",
    "def plot_coef(coef):\n",
    "    x = []; y = []\n",
    "    for item in coef:\n",
    "        x.append(item[0])\n",
    "        y.append(item[1])\n",
    "\n",
    "    f, ax = plt.subplots(figsize=(20, 15))\n",
    "    sns.barplot(x,y,alpha=0.5)\n",
    "    ax.set_title('Feature Importance for Model : Logistic Regression')\n",
    "    ax.set(xlabel='Column Name', ylabel='Feature Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
      "          penalty='l2', random_state=777, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "==================================================\n",
      "# Coefficients for target_num == 0\n",
      "[  0.00000000e+00  -1.44479305e-04  -1.72440483e-03  -6.62831797e-05\n",
      "  -4.00738642e-03  -1.37587306e-04   9.43799153e-05  -9.75453910e-03\n",
      "  -4.57973205e-05   1.71631976e-05  -4.77794835e-05   5.31567487e-05\n",
      "  -9.51667325e-05   1.64720342e-05  -4.82183632e-05   2.95537254e-03\n",
      "   8.31537519e-07  -1.12444979e-03  -1.08733896e-03  -1.07982690e-04\n",
      "  -1.84225687e-07   4.04364051e-06]\n",
      "--------------------------------------------------\n",
      "# Mapped to Column Name\n",
      "     0.0 \t fecha_dato\n",
      "     -0.00014 \t ind_empleado\n",
      "     -0.00172 \t pais_residencia\n",
      "     -7e-05 \t sexo\n",
      "     -0.00401 \t age\n",
      "     -0.00014 \t fecha_alta\n",
      "     9e-05 \t ind_nuevo\n",
      "     -0.00975 \t antiguedad\n",
      "     -5e-05 \t indrel\n",
      "     2e-05 \t ult_fec_cli_1t\n",
      "     -5e-05 \t indrel_1mes\n",
      "     5e-05 \t tiprel_1mes\n",
      "     -0.0001 \t indresi\n",
      "     2e-05 \t indext\n",
      "     -5e-05 \t conyuemp\n",
      "     0.00296 \t canal_entrada\n",
      "     0.0 \t indfall\n",
      "     -0.00112 \t cod_prov\n",
      "     -0.00109 \t nomprov\n",
      "     -0.00011 \t ind_actividad_cliente\n",
      "     -0.0 \t renta\n",
      "     0.0 \t segmento\n",
      "--------------------------------------------------\n",
      "# Sorted Feature Importance\n",
      "     0.00975 \t antiguedad\n",
      "     0.00401 \t age\n",
      "     0.00296 \t canal_entrada\n",
      "     0.00172 \t pais_residencia\n",
      "     0.00112 \t cod_prov\n",
      "     0.00109 \t nomprov\n",
      "     0.00014 \t ind_empleado\n",
      "     0.00014 \t fecha_alta\n",
      "     0.00011 \t ind_actividad_cliente\n",
      "     0.0001 \t indresi\n",
      "     9e-05 \t ind_nuevo\n",
      "     7e-05 \t sexo\n",
      "     5e-05 \t tiprel_1mes\n",
      "     5e-05 \t conyuemp\n",
      "     5e-05 \t indrel_1mes\n",
      "     5e-05 \t indrel\n",
      "     2e-05 \t ult_fec_cli_1t\n",
      "     2e-05 \t indext\n",
      "     0.0 \t segmento\n",
      "     0.0 \t indfall\n",
      "     0.0 \t renta\n",
      "     0.0 \t fecha_dato\n"
     ]
    }
   ],
   "source": [
    "# 모델 상세 보기\n",
    "coef = observe_model_lr(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 캐글 결과물 출력을 위한 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "print('='*50)\n",
    "print('# Test shape : {}'.format(tst.shape))\n",
    "\n",
    "model = LogisticRegression(n_jobs=-1, random_state=777)\n",
    "model.fit(trn,target)\n",
    "\n",
    "preds = model.predict_proba(tst)\n",
    "preds = np.fliplr(np.argsort(preds, axis=1)) # 왼쪽이 제일 큰 값이 나오게 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n",
    "        'ind_cder_fin_ult1', 'ind_cno_fin_ult1',  'ind_ctju_fin_ult1',\n",
    "        'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
    "        'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n",
    "        'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n",
    "        'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n",
    "        'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n",
    "        'ind_nomina_ult1',   'ind_nom_pens_ult1', 'ind_recibo_ult1']\n",
    "target_cols = [cols[i] for i, col in enumerate(cols) if i in rem_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_preds = []\n",
    "for pred in preds:\n",
    "    top_products = []\n",
    "    for i, product in enumerate(pred):\n",
    "        top_products.append(target_cols[product])\n",
    "        if i == 6:\n",
    "            break\n",
    "    final_preds.append(' '.join(top_products))\n",
    "\n",
    "out_df = pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "file_name = datetime.now().strftime(\"result_%Y%m%d%H%M%S\") + '.csv'\n",
    "out_df.to_csv(os.path.join('../output',file_name), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
